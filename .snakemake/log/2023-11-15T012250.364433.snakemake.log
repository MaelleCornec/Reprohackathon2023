Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Singularity containers: ignored
Job stats:
job         count    min threads    max threads
--------  -------  -------------  -------------
all             1              1              1
counting        1              1              1
mapping         6              1              1
total           8              1              1

Select jobs to execute...

[Wed Nov 15 01:22:50 2023]
rule mapping:
    input: data_trim/SRR10379723_trimmed.fq
    output: data_map/SRR10379723.bam
    jobid: 6
    wildcards: sample=SRR10379723
    resources: tmpdir=/tmp


[Wed Nov 15 01:22:50 2023]
rule mapping:
    input: data_trim/SRR10379722_trimmed.fq
    output: data_map/SRR10379722.bam
    jobid: 4
    wildcards: sample=SRR10379722
    resources: tmpdir=/tmp


[Wed Nov 15 01:22:50 2023]
rule mapping:
    input: data_trim/SRR10379725_trimmed.fq
    output: data_map/SRR10379725.bam
    jobid: 10
    wildcards: sample=SRR10379725
    resources: tmpdir=/tmp


[Wed Nov 15 01:22:50 2023]
rule mapping:
    input: data_trim/SRR10379726_trimmed.fq
    output: data_map/SRR10379726.bam
    jobid: 12
    wildcards: sample=SRR10379726
    resources: tmpdir=/tmp


[Wed Nov 15 01:22:50 2023]
rule mapping:
    input: data_trim/SRR10379724_trimmed.fq
    output: data_map/SRR10379724.bam
    jobid: 8
    wildcards: sample=SRR10379724
    resources: tmpdir=/tmp


[Wed Nov 15 01:22:50 2023]
rule mapping:
    input: data_trim/SRR10379721_trimmed.fq
    output: data_map/SRR10379721.bam
    jobid: 2
    wildcards: sample=SRR10379721
    resources: tmpdir=/tmp

[Wed Nov 15 01:22:51 2023]
Finished job 4.
1 of 8 steps (12%) done
[Wed Nov 15 01:22:51 2023]
Finished job 6.
2 of 8 steps (25%) done
[Wed Nov 15 01:22:51 2023]
Finished job 8.
3 of 8 steps (38%) done
[Wed Nov 15 01:22:51 2023]
Finished job 2.
4 of 8 steps (50%) done
[Wed Nov 15 01:22:51 2023]
Finished job 10.
5 of 8 steps (62%) done
[Wed Nov 15 01:22:51 2023]
Finished job 12.
6 of 8 steps (75%) done
Select jobs to execute...

[Wed Nov 15 01:22:51 2023]
rule counting:
    input: data_map/SRR10379721.bam, data_map/SRR10379722.bam, data_map/SRR10379723.bam, data_map/SRR10379724.bam, data_map/SRR10379725.bam, data_map/SRR10379726.bam, genome/reference.gff
    output: data_comptage/counts.txt
    jobid: 1
    resources: tmpdir=/tmp

[Wed Nov 15 01:22:51 2023]
Error in rule counting:
    jobid: 1
    output: data_comptage/counts.txt
    shell:
        featureCounts --extraAttributes Name -t gene -g -s 1 ID -F GTF -T 4 -a genome/reference.gff -o data_comptage/counts.txt data_map/SRR10379721.bam data_map/SRR10379722.bam data_map/SRR10379723.bam data_map/SRR10379724.bam data_map/SRR10379725.bam data_map/SRR10379726.bam
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/ubuntu/Reprohackathon2023/.snakemake/log/2023-11-15T012250.364433.snakemake.log
