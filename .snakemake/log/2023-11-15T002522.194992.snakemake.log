Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Singularity containers: ignored
Job stats:
job               count    min threads    max threads
--------------  -------  -------------  -------------
all                   1              1              1
annotation_gen        1              1              1
counting              1              1              1
genome                1              1              1
indexing              1              1              1
mapping               6              1              1
trimming              6              1              1
total                17              1              1

Select jobs to execute...

[Wed Nov 15 00:25:22 2023]
rule trimming:
    input: data40000/SRR10379721.fastq
    output: data_trim/SRR10379721_trimmed.fq
    jobid: 5
    wildcards: echantillon=SRR10379721
    resources: tmpdir=/tmp


[Wed Nov 15 00:25:22 2023]
rule genome:
    output: genome/reference.fasta
    jobid: 4
    resources: tmpdir=/tmp


[Wed Nov 15 00:25:22 2023]
rule annotation_gen:
    output: genome/reference.gff
    jobid: 16
    resources: tmpdir=/tmp


[Wed Nov 15 00:25:22 2023]
rule trimming:
    input: data40000/SRR10379722.fastq
    output: data_trim/SRR10379722_trimmed.fq
    jobid: 7
    wildcards: echantillon=SRR10379722
    resources: tmpdir=/tmp


[Wed Nov 15 00:25:22 2023]
rule trimming:
    input: data40000/SRR10379723.fastq
    output: data_trim/SRR10379723_trimmed.fq
    jobid: 9
    wildcards: echantillon=SRR10379723
    resources: tmpdir=/tmp


[Wed Nov 15 00:25:22 2023]
rule trimming:
    input: data40000/SRR10379724.fastq
    output: data_trim/SRR10379724_trimmed.fq
    jobid: 11
    wildcards: echantillon=SRR10379724
    resources: tmpdir=/tmp


[Wed Nov 15 00:25:22 2023]
rule trimming:
    input: data40000/SRR10379725.fastq
    output: data_trim/SRR10379725_trimmed.fq
    jobid: 13
    wildcards: echantillon=SRR10379725
    resources: tmpdir=/tmp


[Wed Nov 15 00:25:22 2023]
rule trimming:
    input: data40000/SRR10379726.fastq
    output: data_trim/SRR10379726_trimmed.fq
    jobid: 15
    wildcards: echantillon=SRR10379726
    resources: tmpdir=/tmp

[Wed Nov 15 00:25:23 2023]
Finished job 13.
1 of 17 steps (6%) done
[Wed Nov 15 00:25:23 2023]
Finished job 7.
2 of 17 steps (12%) done
[Wed Nov 15 00:25:23 2023]
Finished job 5.
3 of 17 steps (18%) done
[Wed Nov 15 00:25:23 2023]
Finished job 9.
4 of 17 steps (24%) done
[Wed Nov 15 00:25:23 2023]
Finished job 11.
5 of 17 steps (29%) done
[Wed Nov 15 00:25:23 2023]
Finished job 15.
6 of 17 steps (35%) done
[Wed Nov 15 00:25:24 2023]
Finished job 4.
7 of 17 steps (41%) done
Select jobs to execute...

[Wed Nov 15 00:25:24 2023]
rule indexing:
    input: genome/reference.fasta
    output: index/indexation
    jobid: 3
    resources: tmpdir=/tmp

[Wed Nov 15 00:25:24 2023]
Error in rule indexing:
    jobid: 3
    output: index/indexation
    shell:
        bowtie-build genome/reference.fasta index/indexation
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

[Wed Nov 15 00:25:45 2023]
Finished job 16.
8 of 17 steps (47%) done
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/ubuntu/Reprohackathon2023/.snakemake/log/2023-11-15T002522.194992.snakemake.log
