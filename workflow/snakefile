# Chargement du fichier de configuration config.yaml
configfile:
    "config/config.yaml"

# Snakemake définit par défaut la première règle comme la cible.
# A l'état actuel, je n'ai pas encore inclus les script python dans le snakefile, donc ma cible est le fichier count.
# Comme ça, quand on exécute la commande snakemake --cores, 
# Il exécutera récursivement toutes les règles nécessaires pour obtenir le fichier count
rule all:
    input:
        "scripts/MA-plot_all_genes.png",
        "scripts/PCA_all_genes.png",
        "scripts/Volcano_plot_all_genes.png",
        "scripts/MA-plot_translation_genes.png",
        "scripts/PCA_translation_genes.png",
        "scripts/Volcano_plot_translation_genes.png"
    output:
        "reports/MA-plot_all_genes.png",
        "reports/PCA_all_genes.png",
        "reports/Volcano_plot_all_genes.png",
        "reports/MA-plot_translation_genes.png",
        "reports/PCA_translation_genes.png",
        "reports/Volcano_plot_translation_genes.png"
    message:
        "Déplacement des figures dans le dossier reports"
    shell:
        """
        mv scripts/*.png reports
        """

# Téléchargement des 6 échantillons à analyser
rule downloading:
    output:
        "data/{sample}.fastq"
    message:
        "Téléchargement de {wildcards.sample}"
    container:
        "docker://suzannegtx/sra-toolkit:2.10.0"
    log:
        "logs/downloading/{sample}.log"
    shell:
        """
        (fasterq-dump --threads 8 --progress {wildcards.sample} -O data) 2> {log}
        """

# Découpe des morceaux d'échantillons qui sont trop incertains et élimination des échantillons de moins de 25 nucléotides
rule trimming:
    input:
        "data/{sample}.fastq"
    output:
        "data_trim/{sample}_trimmed.fq"
    message:
        "Nettoyage de {wildcards.sample}"
    container:
        "docker://suzannegtx/trimgalore-cutadapt:0.6.4"
    log:
        "logs/trimming/{sample}.log"
    shell:
        """
        (trim_galore -q 20 --phred33 --length 25 {input} -O data_trim
        rm {input}
        mv data_trim/*.txt logs/trimming
        rm data_trim) 2> {log}
        """

# Téléchargement du génome de référence dans un dossier reference
rule genome:
    output:
        "genome/reference.fasta"
    params:
        config["linkfasta"]
    message:
        "Téléchargement du génome de référence"
    shell:
        """
        wget -q -O {output} "{params}"
        """

# Création de l'index sur le génome de référence
rule indexing:
    input:
        "genome/reference.fasta"
    output:
        "index/indexation.1.ebwt",
        "index/indexation.2.ebwt",
        "index/indexation.3.ebwt",
        "index/indexation.4.ebwt",
        "index/indexation.rev.1.ebwt",
        "index/indexation.rev.2.ebwt"
    message:
        "Indexation du génome de référence"
    container:
        "docker://suzannegtx/bowtie:0.12.7"
    shell: 
        """
        bowtie-build {input} index/indexation
        """

# Création des fichiers sam
rule samming:
    input:
        ech={"data_trim/{sample}_trimmed.fq"},
        ind={"index/indexation.1.ebwt",
        "index/indexation.2.ebwt",
        "index/indexation.3.ebwt",
        "index/indexation.4.ebwt",
        "index/indexation.rev.1.ebwt",
        "index/indexation.rev.2.ebwt"}
    output:
        "data_sam/{sample}.sam"
    message:
        "Première étape du mapping de {wildcards.sample}"
    container:
        "docker://suzannegtx/bowtie:0.12.7"
    log:
        "logs/samming/{sample}.log"
    shell:
        """
        (bowtie -x -s index/indexation {input.ech} -S {output}
        rm {input.ech}) 2> {log}
        """

# Création des fichiers bam
rule bamming:
    input:
        "data_sam/{sample}.sam"
    output:
        "data_bam/{sample}.bam"
    message:
        "Deuwième étape du mapping de {wildcards.sample}"
    container:
        "docker://pegi3s/samtools_bcftools:1.9"
    shell:
        """
        samtools sort -O bam -o {output} {input}
        rm {input}
        """

# Cartographie des échantillons grâce à l'index fait sur le génome de référence
rule mapping:
    input:
        "data_bam/{sample}.bam"      
    output:
        "data_bam/{sample}.bam.bai"
    message:
        "Troisième étape du mapping de {wildcards.sample}"
    container:
        "docker://pegi3s/samtools_bcftools:1.9"
    shell:
        """
        samtools index {input}
        """

# Téléchargement des annotations du génome de référence dans un dossier reference
rule annotation_gen:
    output:
        "genome/reference.gff"
    params:
        config["linkgff"]
    message:
        "Téléchargement des annotations du génome de référence"
    log:
        "logs/downloading/reference_gff.log" 
    shell:
        """
        (wget -O {output} "{params}") 2> {log}
        """

# Dénombrement des motifs présents sur les échantillons grâce aux annotations du génome de référence
rule counting:
    input:
        bam=expand("data_bam/{sample}.bam", sample=config["samples"]),
        bai=expand("data_bam/{sample}.bam.bai", sample=config["samples"]),
        ref="genome/reference.gff"
    output:
        "scripts/genes/counts.txt"
    message:
        "Dénombrement des motifs"
    container:
        "docker://suzannegtx/subreads-featurecounts:1.4.6-p3"
    log:
        "logs/counting.log"
    shell:
        """
        (featureCounts -t gene -g ID -s 1 -a {input.ref} -o {output} {input.bam}
        rm data_bam) 2> {log}
        """

# Analyse des échantillons en connaissant le nom des gènes
rule analysis:
    input:
        "scripts/genes/counts.txt",
        "scripts/genes/Gene_Names_1col_true.csv"
    output:
        "scripts/MA-plot_all_genes.png",
        "scripts/PCA_all_genes.png",
        "scripts/Volcano_plot_all_genes.png",
        "scripts/MA-plot_translation_genes.png",
        "scripts/PCA_translation_genes.png",
        "scripts/Volcano_plot_translation_genes.png"
    message:
        "Réalisation des figures"
    container:
        "docker://pegi3s/r_deseq2:1.32.0_v2"
    script:
        "scripts/R_script_Final_2.R"
